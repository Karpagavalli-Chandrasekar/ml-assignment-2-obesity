{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Programming Assignment\n",
    "## Logistic regression\n",
    "\n",
    "**Student Name:** Karpagavalli Chandrasekar \n",
    "**Student ID:** 2025aa05318\n",
    "**Date:** 10/1/2026\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è IMPORTANT INSTRUCTIONS\n",
    "\n",
    "1. **Complete ALL sections** marked with `TODO`\n",
    "2. **DO NOT modify** the `get_assignment_results()` function structure\n",
    "3. **Fill in all values accurately** - these will be auto-verified\n",
    "4. **After submission**, you'll receive a verification quiz based on YOUR results\n",
    "5. **Run all cells** before submitting (Kernel ‚Üí Restart & Run All)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Loads CSV, drops nulls \n",
    "Creates binary target Obese using target_map \n",
    "Encodes yes/no risk factors to 0/1 \n",
    "One-hot encodes multi-class categorical columns \n",
    "Trains logistic regression \n",
    "Computes predictions and prints metrics \n",
    "\"\"\"\n",
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "print('‚úì Libraries imported successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Dataset Selection and Loading\n",
    "\n",
    "**Requirements:**\n",
    "- ‚â•500 samples\n",
    "- ‚â•5 features\n",
    "- Public dataset (UCI/Kaggle)\n",
    "- Regression OR Classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ObesityDataset.csv\n",
      "Source: Kaggle Repository\n",
      "Samples: 546, Features: 12\n",
      "Problem Type: Binary_classification\n",
      "Primary Metric: ('recall', 'accuracy', 'precision', 'F1', 'AUC Score')\n"
     ]
    }
   ],
   "source": [
    "# TODO: Load your dataset\n",
    "# Example: data = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Dataset information (TODO: Fill these)\n",
    "dataset_name = 'ObesityDataset.csv'  # e.g., \"Breast Cancer Wisconsin\"\n",
    "dataset_source = \"Kaggle Repository\"  # e.g., \"UCI ML Repository\"\n",
    "n_samples = 546     # Total number of rows\n",
    "n_features = 12     # Number of features (excluding target)\n",
    "problem_type = \"Binary_classification\"  # \"regression\" or \"binary_classification\" or \"multiclass_classification\"\n",
    "\n",
    "# Problem statement (TODO: Write 2-3 sentences)\n",
    "problem_statement = \"\"\"\n",
    "With this assignment, going to predict the patient obesity level\n",
    "\"\"\"\n",
    "\n",
    "# Primary evaluation metric (TODO: Fill this)\n",
    "primary_metric = \"recall\",\"accuracy\",\"precision\",\"F1\",\"AUC Score\"  # e.g., \"recall\", \"accuracy\", \"rmse\", \"r2\"\n",
    "\n",
    "# Metric justification (TODO: Write 2-3 sentences)\n",
    "metric_justification = \"\"\"\n",
    "TODO: Explain why you chose this metric.\n",
    "\n",
    "These mesures are used to classifty the passenger whether he/she has obesity.\n",
    "\n",
    "In the obesity dataset:\n",
    "NObeyesdad value\t                          Meaning\n",
    "Normal_Weight / Insufficient_Weight\t          NOT obese (0)\n",
    "Overweight / Obesity_Type_I/II/III\t          OBESE (1)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Dataset: {dataset_name}\")\n",
    "print(f\"Source: {dataset_source}\")\n",
    "print(f\"Samples: {n_samples}, Features: {n_features}\")\n",
    "print(f\"Problem Type: {problem_type}\")\n",
    "print(f\"Primary Metric: {primary_metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Data Preprocessing\n",
    "\n",
    "Preprocess your data:\n",
    "1. Handle missing values\n",
    "2. Encode categorical variables\n",
    "3. Split into train/test sets\n",
    "4. Scale features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 1: LOGISTIC REGRESSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset shape: (2111, 17)\n",
      "\n",
      "First few rows:\n",
      "   Gender   Age  Height  Weight family_history_with_overweight FAVC  FCVC  \\\n",
      "0  Female  21.0    1.62    64.0                            yes   no   2.0   \n",
      "1  Female  21.0    1.52    56.0                            yes   no   3.0   \n",
      "2    Male  23.0    1.80    77.0                            yes   no   2.0   \n",
      "3    Male  27.0    1.80    87.0                             no   no   3.0   \n",
      "4    Male  22.0    1.78    89.8                             no   no   2.0   \n",
      "\n",
      "   NCP       CAEC SMOKE  CH2O  SCC  FAF  TUE        CALC  \\\n",
      "0  3.0  Sometimes    no   2.0   no  0.0  1.0          no   \n",
      "1  3.0  Sometimes   yes   3.0  yes  3.0  0.0   Sometimes   \n",
      "2  3.0  Sometimes    no   2.0   no  2.0  1.0  Frequently   \n",
      "3  3.0  Sometimes    no   2.0   no  2.0  0.0  Frequently   \n",
      "4  1.0  Sometimes    no   2.0   no  0.0  0.0   Sometimes   \n",
      "\n",
      "                  MTRANS           NObeyesdad  \n",
      "0  Public_Transportation        Normal_Weight  \n",
      "1  Public_Transportation        Normal_Weight  \n",
      "2  Public_Transportation        Normal_Weight  \n",
      "3                Walking   Overweight_Level_I  \n",
      "4  Public_Transportation  Overweight_Level_II  \n",
      "\n",
      "Check null values:\n",
      "Gender                            0\n",
      "Age                               0\n",
      "Height                            0\n",
      "Weight                            0\n",
      "family_history_with_overweight    0\n",
      "FAVC                              0\n",
      "FCVC                              0\n",
      "NCP                               0\n",
      "CAEC                              0\n",
      "SMOKE                             0\n",
      "CH2O                              0\n",
      "SCC                               0\n",
      "FAF                               0\n",
      "TUE                               0\n",
      "CALC                              0\n",
      "MTRANS                            0\n",
      "NObeyesdad                        0\n",
      "dtype: int64\n",
      "\n",
      "After preprocessing (X columns):\n",
      "['Age', 'Height', 'Weight', 'family_history_with_overweight', 'FAVC', 'FCVC', 'NCP', 'SMOKE', 'CH2O', 'SCC', 'FAF', 'TUE', 'Gender_Male', 'CAEC_Frequently', 'CAEC_Sometimes', 'CAEC_no', 'CALC_Frequently', 'CALC_Sometimes', 'CALC_no', 'MTRANS_Bike'] ...\n",
      "X shape: (2111, 23)\n",
      "\n",
      "Train samples: 1688\n",
      "Test samples : 423\n",
      "Split ratio  : 80.0%\n",
      "\n",
      "Model evaluation done\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"ObesityDataset.csv\")\n",
    "print(f\"\\nDataset shape: {data.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(data.head())\n",
    "\n",
    "# Handle missing values\n",
    "print(\"\\nCheck null values:\")\n",
    "print(data.isnull().sum())\n",
    "data = data.dropna()\n",
    "\n",
    "# ---- 1) Create binary target y ----\n",
    "target_map = {\n",
    "    \"Insufficient_Weight\": 0,\n",
    "    \"Normal_Weight\": 0,\n",
    "    \"Overweight_Level_I\": 1,\n",
    "    \"Overweight_Level_II\": 1,\n",
    "    \"Obesity_Type_I\": 1,\n",
    "    \"Obesity_Type_II\": 1,\n",
    "    \"Obesity_Type_III\": 1\n",
    "}\n",
    "data[\"Obese\"] = data[\"NObeyesdad\"].map(target_map)\n",
    "\n",
    "# Safety check: ensure mapping worked for all rows\n",
    "if data[\"Obese\"].isnull().any():\n",
    "    unmapped = data.loc[data[\"Obese\"].isnull(), \"NObeyesdad\"].unique()\n",
    "    raise ValueError(f\"Unmapped target classes found in NObeyesdad: {unmapped}\")\n",
    "\n",
    "y = data[\"Obese\"].astype(int)  # keep as 1-D for sklearn\n",
    "\n",
    "# ---- 2) Build features X ----\n",
    "X = data.drop(columns=[\"NObeyesdad\", \"Obese\"]).copy()\n",
    "\n",
    "# Binary yes/no columns (map safely in case of 'Yes'/'No' etc.)\n",
    "binary_cols = [\"family_history_with_overweight\", \"FAVC\", \"SMOKE\", \"SCC\"]\n",
    "for col in binary_cols:\n",
    "    X[col] = X[col].astype(str).str.strip().str.lower().map({\"yes\": 1, \"no\": 0})\n",
    "\n",
    "# Safety check for unexpected values in binary columns\n",
    "for col in binary_cols:\n",
    "    if X[col].isnull().any():\n",
    "        bad_vals = data.loc[X[col].isnull(), col].unique()\n",
    "        raise ValueError(f\"Unexpected values in {col}: {bad_vals}\")\n",
    "\n",
    "# One-hot encode multi-category columns\n",
    "multi_cols = [\"Gender\", \"CAEC\", \"CALC\", \"MTRANS\"]\n",
    "X = pd.get_dummies(X, columns=multi_cols, drop_first=True)\n",
    "\n",
    "# Ensure numeric type\n",
    "X = X.astype(float)\n",
    "\n",
    "print(\"\\nAfter preprocessing (X columns):\")\n",
    "print(X.columns.tolist()[:20], \"...\")  # preview first 20\n",
    "print(\"X shape:\", X.shape)\n",
    "\n",
    "# ---- 3) Train-test split ----\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ---- 4) Train Logistic Regression ----\n",
    "model = LogisticRegression(max_iter=2000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ---- 5) Predictions ----\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "train_samples = X_train.shape[0]\n",
    "test_samples = X_test.shape[0]\n",
    "train_test_ratio = train_samples / (train_samples + test_samples)\n",
    "\n",
    "\n",
    "print(f\"\\nTrain samples: {train_samples}\")\n",
    "print(f\"Test samples : {test_samples}\")\n",
    "print(f\"Split ratio  : {train_test_ratio:.1%}\")\n",
    "\n",
    "print(f\"\\nModel evaluation done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_performance(y_true, y_pred, y_prob, threshold=0.5):\n",
    "    from sklearn.metrics import (\n",
    "        accuracy_score, precision_score, recall_score, f1_score,\n",
    "        roc_auc_score, matthews_corrcoef, confusion_matrix, classification_report\n",
    "    )\n",
    "    import numpy as np\n",
    "\n",
    "    # Apply threshold on probability\n",
    "    y_pred_thr = (y_prob >= threshold).astype(int)\n",
    "\n",
    "    acc  = accuracy_score(y_true, y_pred_thr)\n",
    "    prec = precision_score(y_true, y_pred_thr, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred_thr, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred_thr, zero_division=0)\n",
    "    auc  = roc_auc_score(y_true, y_prob)\n",
    "    mcc  = matthews_corrcoef(y_true, y_pred_thr)\n",
    "    cm   = confusion_matrix(y_true, y_pred_thr)\n",
    "\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    specificity = tn / (tn + fp) if (tn + fp) else 0\n",
    "    fpr = fp / (fp + tn) if (fp + tn) else 0\n",
    "    fnr = fn / (fn + tp) if (fn + tp) else 0\n",
    "\n",
    "    print(\"\\n======== MODEL PERFORMANCE ========\")\n",
    "    print(f\"Threshold   : {threshold:.2f}\")\n",
    "    print(f\"Accuracy    : {acc:.4f}\")\n",
    "    print(f\"Precision   : {prec:.4f}\")\n",
    "    print(f\"Recall      : {rec:.4f}\")\n",
    "    print(f\"F1 Score    : {f1:.4f}\")\n",
    "    print(f\"AUC         : {auc:.4f}\")\n",
    "    print(f\"MCC         : {mcc:.4f}\")\n",
    "    print(f\"Specificity : {specificity:.4f}\")\n",
    "    print(f\"FPR         : {fpr:.4f}\")\n",
    "    print(f\"FNR         : {fnr:.4f}\")\n",
    "\n",
    "    print(\"\\nConfusion Matrix [TN FP; FN TP]:\")\n",
    "    print(cm)\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred_thr, digits=4))\n",
    "    print(\"===================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " LOGISTIC REGRESSION METRICS\n",
      "\n",
      "======== MODEL PERFORMANCE ========\n",
      "Threshold   : 0.50\n",
      "Accuracy    : 0.9764\n",
      "Precision   : 0.9808\n",
      "Recall      : 0.9871\n",
      "F1 Score    : 0.9840\n",
      "AUC         : 0.9953\n",
      "MCC         : 0.9390\n",
      "Specificity : 0.9464\n",
      "FPR         : 0.0536\n",
      "FNR         : 0.0129\n",
      "\n",
      "Confusion Matrix [TN FP; FN TP]:\n",
      "[[106   6]\n",
      " [  4 307]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9636    0.9464    0.9550       112\n",
      "           1     0.9808    0.9871    0.9840       311\n",
      "\n",
      "    accuracy                         0.9764       423\n",
      "   macro avg     0.9722    0.9668    0.9695       423\n",
      "weighted avg     0.9763    0.9764    0.9763       423\n",
      "\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n LOGISTIC REGRESSION METRICS\")\n",
    "print_model_performance(y_test, y_pred, y_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 2: DECISION TREE CLASSIFIER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DECISION TREE PERFORMANCE\n",
      "\n",
      "======== MODEL PERFORMANCE ========\n",
      "Threshold   : 0.50\n",
      "Accuracy    : 0.9764\n",
      "Precision   : 0.9778\n",
      "Recall      : 0.9904\n",
      "F1 Score    : 0.9840\n",
      "AUC         : 0.9923\n",
      "MCC         : 0.9389\n",
      "Specificity : 0.9375\n",
      "FPR         : 0.0625\n",
      "FNR         : 0.0096\n",
      "\n",
      "Confusion Matrix [TN FP; FN TP]:\n",
      "[[105   7]\n",
      " [  3 308]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9722    0.9375    0.9545       112\n",
      "           1     0.9778    0.9904    0.9840       311\n",
      "\n",
      "    accuracy                         0.9764       423\n",
      "   macro avg     0.9750    0.9639    0.9693       423\n",
      "weighted avg     0.9763    0.9764    0.9762       423\n",
      "\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DECISION TREE CLASSIFIER\n",
    "\"\"\"\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    max_depth=6,           # prevents overfitting\n",
    "    min_samples_leaf=20,   # improves generalization\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "dt_pred = dt_model.predict(X_test)\n",
    "dt_prob = dt_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"\\nDECISION TREE PERFORMANCE\")\n",
    "print_model_performance(y_test, dt_pred, dt_prob, threshold=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 3: K-NEAREST NEIGHBOR CLASSIFIER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN CLASSIFIER PERFORMANCE\n",
      "\n",
      "======== MODEL PERFORMANCE ========\n",
      "Threshold   : 0.50\n",
      "Accuracy    : 0.9149\n",
      "Precision   : 0.9338\n",
      "Recall      : 0.9518\n",
      "F1 Score    : 0.9427\n",
      "AUC         : 0.9448\n",
      "MCC         : 0.7781\n",
      "Specificity : 0.8125\n",
      "FPR         : 0.1875\n",
      "FNR         : 0.0482\n",
      "\n",
      "Confusion Matrix [TN FP; FN TP]:\n",
      "[[ 91  21]\n",
      " [ 15 296]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8585    0.8125    0.8349       112\n",
      "           1     0.9338    0.9518    0.9427       311\n",
      "\n",
      "    accuracy                         0.9149       423\n",
      "   macro avg     0.8961    0.8821    0.8888       423\n",
      "weighted avg     0.9138    0.9149    0.9141       423\n",
      "\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "knn_model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),        # KNN is distance based\n",
    "    (\"knn\", KNeighborsClassifier(n_neighbors=7, metric=\"minkowski\"))\n",
    "])\n",
    "\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "knn_prob = knn_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"\\nKNN CLASSIFIER PERFORMANCE\")\n",
    "print_model_performance(y_test, knn_pred, knn_prob, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 4: NAIVE BAYES CLASSIFIER - GAUSSIAN OR MULTINOMIAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NAIVE BAYES (GaussianNB) PERFORMANCE\n",
      "\n",
      "======== MODEL PERFORMANCE ========\n",
      "Threshold   : 0.50\n",
      "Accuracy    : 0.8723\n",
      "Precision   : 0.9298\n",
      "Recall      : 0.8939\n",
      "F1 Score    : 0.9115\n",
      "AUC         : 0.9292\n",
      "MCC         : 0.6847\n",
      "Specificity : 0.8125\n",
      "FPR         : 0.1875\n",
      "FNR         : 0.1061\n",
      "\n",
      "Confusion Matrix [TN FP; FN TP]:\n",
      "[[ 91  21]\n",
      " [ 33 278]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7339    0.8125    0.7712       112\n",
      "           1     0.9298    0.8939    0.9115       311\n",
      "\n",
      "    accuracy                         0.8723       423\n",
      "   macro avg     0.8318    0.8532    0.8413       423\n",
      "weighted avg     0.8779    0.8723    0.8743       423\n",
      "\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "nb_pred = nb_model.predict(X_test)\n",
    "nb_prob = nb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nNAIVE BAYES (GaussianNB) PERFORMANCE\")\n",
    "print_model_performance(y_test, nb_pred, nb_prob, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 6: ENSEMBLE MODEL - RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RANDOM FOREST ENSEMBLE PERFORMANCE\n",
      "\n",
      "======== MODEL PERFORMANCE ========\n",
      "Threshold   : 0.50\n",
      "Accuracy    : 0.9669\n",
      "Precision   : 0.9775\n",
      "Recall      : 0.9775\n",
      "F1 Score    : 0.9775\n",
      "AUC         : 0.9945\n",
      "MCC         : 0.9150\n",
      "Specificity : 0.9375\n",
      "FPR         : 0.0625\n",
      "FNR         : 0.0225\n",
      "\n",
      "Confusion Matrix [TN FP; FN TP]:\n",
      "[[105   7]\n",
      " [  7 304]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9375    0.9375    0.9375       112\n",
      "           1     0.9775    0.9775    0.9775       311\n",
      "\n",
      "    accuracy                         0.9669       423\n",
      "   macro avg     0.9575    0.9575    0.9575       423\n",
      "weighted avg     0.9669    0.9669    0.9669       423\n",
      "\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=15,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_prob = rf_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"\\nRANDOM FOREST ENSEMBLE PERFORMANCE\")\n",
    "print_model_performance(y_test, rf_pred, rf_prob, threshold=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 5: ENSEMBLE MODEL - XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\kchandrase37\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (3.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\kchandrase37\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from xgboost) (2.3.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\kchandrase37\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from xgboost) (1.16.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBOOST ENSEMBLE PERFORMANCE\n",
      "\n",
      "======== MODEL PERFORMANCE ========\n",
      "Threshold   : 0.50\n",
      "Accuracy    : 0.9905\n",
      "Precision   : 0.9968\n",
      "Recall      : 0.9904\n",
      "F1 Score    : 0.9935\n",
      "AUC         : 0.9998\n",
      "MCC         : 0.9759\n",
      "Specificity : 0.9911\n",
      "FPR         : 0.0089\n",
      "FNR         : 0.0096\n",
      "\n",
      "Confusion Matrix [TN FP; FN TP]:\n",
      "[[111   1]\n",
      " [  3 308]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9737    0.9911    0.9823       112\n",
      "           1     0.9968    0.9904    0.9935       311\n",
      "\n",
      "    accuracy                         0.9905       423\n",
      "   macro avg     0.9852    0.9907    0.9879       423\n",
      "weighted avg     0.9907    0.9905    0.9906       423\n",
      "\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "xgb_prob = xgb_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"\\nXGBOOST ENSEMBLE PERFORMANCE\")\n",
    "print_model_performance(y_test, xgb_pred, xgb_prob, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## ‚≠ê REQUIRED: Structured Output Function\n",
    "\n",
    "### **DO NOT MODIFY THE STRUCTURE BELOW**\n",
    "\n",
    "This function will be called by the auto-grader. Fill in all values accurately based on your actual results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assignment_results():\n",
    "    \"\"\"\n",
    "    Return all assignment results in structured format.\n",
    "    \n",
    "    CRITICAL: Fill in ALL values based on your actual results!\n",
    "    This will be automatically extracted and validated.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate loss convergence flags\n",
    "    baseline_initial_loss = 1.0  # TODO: baseline_model.loss_history[0]\n",
    "    baseline_final_loss = 0.314557053602261    # TODO: baseline_model.loss_history[-1]\n",
    "    mlp_initial_loss = 6.428935842411034       # TODO: mlp_model.loss_history[0]\n",
    "    mlp_final_loss = 0.21074853871008836         # TODO: mlp_model.loss_history[-1]\n",
    "\n",
    "    results = {\n",
    "        # ===== Dataset Information =====\n",
    "        'dataset_name': dataset_name,\n",
    "        'dataset_source': dataset_source,\n",
    "        'n_samples': n_samples,\n",
    "        'n_features': n_features,\n",
    "        'problem_type': problem_type,\n",
    "        'problem_statement': problem_statement,\n",
    "        \n",
    "        # ===== Evaluation Setup =====\n",
    "        'primary_metric': primary_metric,\n",
    "        'metric_justification': metric_justification,\n",
    "        'train_samples': train_samples,\n",
    "        'test_samples': test_samples,\n",
    "        'train_test_ratio': train_test_ratio,\n",
    "        \n",
    "        # ===== Baseline Model Results =====\n",
    "        'baseline_model': {\n",
    "            'model_type': 'linear_regression',  # 'linear_regression', 'logistic_regression', or 'softmax_regression'\n",
    "            'learning_rate': 0.01,\n",
    "            'n_iterations': 1000,\n",
    "            'initial_loss': baseline_initial_loss,\n",
    "            'final_loss': baseline_final_loss,\n",
    "            'training_time_seconds': baseline_training_time,\n",
    "            \n",
    "            # Metrics (fill based on your problem type)\n",
    "            'test_accuracy': 0.0,      # For classification\n",
    "            'test_precision': 0.0,     # For classification\n",
    "            'test_recall': 0.0,        # For classification\n",
    "            'test_f1': 0.0,            # For classification\n",
    "            'test_mse': 0.5746,           # For regression\n",
    "            'test_rmse': 0.7580,          # For regression\n",
    "            'test_mae': 0.5579,           # For regression\n",
    "            'test_r2': 0.6495,            # For regression\n",
    "        },\n",
    "        \n",
    "        # ===== MLP Model Results =====\n",
    "        'mlp_model': {\n",
    "            'architecture': mlp_architecture,\n",
    "            'n_hidden_layers': len(mlp_architecture) - 2 if len(mlp_architecture) > 0 else 0,\n",
    "            'total_parameters': 3585,     # TODO: Calculate total weights + biases - 1st 768,64 : 2nd 2048,32 : 3rd 512,16 : 4th 128,8 ; 5th 8,1\n",
    "            'learning_rate': 0.0005,\n",
    "            'n_iterations': 4000,\n",
    "            'initial_loss': mlp_initial_loss,\n",
    "            'final_loss': mlp_final_loss,\n",
    "            'training_time_seconds': mlp_training_time,\n",
    "            \n",
    "            # Metrics\n",
    "            'test_accuracy': 0.0,\n",
    "            'test_precision': 0.0,\n",
    "            'test_recall': 0.0,\n",
    "            'test_f1': 0.0,\n",
    "            'test_mse': 0.5457,\n",
    "            'test_rmse': 0.7387,\n",
    "            'test_mae': 0.5236,\n",
    "            'test_r2': 0.6671,\n",
    "        },\n",
    "        \n",
    "        # ===== Comparison =====\n",
    "        'improvement': 0.0289,            # MLP primary_metric - baseline primary_metric based on MSE\n",
    "        'improvement_percentage': 5.03 ,  # (improvement / baseline) * 100  = 0.0289/0.5746 * 100 = 0.0503\n",
    "        'baseline_better': False,       # True if baseline outperformed MLP\n",
    "        \n",
    "        # ===== Analysis =====\n",
    "        'analysis': analysis_text,\n",
    "        'analysis_word_count': len(analysis_text.split()),\n",
    "        \n",
    "        # ===== Loss Convergence Flags =====\n",
    "        'baseline_loss_decreased': baseline_final_loss < baseline_initial_loss,\n",
    "        'mlp_loss_decreased': mlp_final_loss < mlp_initial_loss,\n",
    "        'baseline_converged': True,  # Optional: True if converged\n",
    "        'mlp_converged': True,\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Your Output\n",
    "\n",
    "Run this cell to verify your results dictionary is complete and properly formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ASSIGNMENT RESULTS SUMMARY\n",
      "======================================================================\n",
      "{\n",
      "  \"dataset_name\": \"Housing.csv\",\n",
      "  \"dataset_source\": \"Kaggle Repository\",\n",
      "  \"n_samples\": 546,\n",
      "  \"n_features\": 12,\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"problem_statement\": \"\\nWith this assignment, going to predict the house prices based on the input features such as \\narea located, no of bed rooms, bath rooms and guest rooms, stories, located in main road or not\\nfurnishing status, airconditioned, hotwater heating and preferred area.\\n\",\n",
      "  \"primary_metric\": [\n",
      "    \"mse\",\n",
      "    \"rmse\",\n",
      "    \"mae\",\n",
      "    \"r2\"\n",
      "  ],\n",
      "  \"metric_justification\": \"\\nTODO: Explain why you chose this metric.\\n\\nMSE measures the average squared difference between predicted and actual house price values and RMSE will give square root of MSE to it will\\nbring error back to the same unit as target price value and will update how big are the errors.\\nWith R2 we can evaluate how much variability in the predicated value from base price value. Thus, have chosen these parameters.\\n\",\n",
      "  \"train_samples\": 0.8,\n",
      "  \"test_samples\": 0.2,\n",
      "  \"train_test_ratio\": 0.8,\n",
      "  \"baseline_model\": {\n",
      "    \"model_type\": \"linear_regression\",\n",
      "    \"learning_rate\": 0.01,\n",
      "    \"n_iterations\": 1000,\n",
      "    \"initial_loss\": 1.0,\n",
      "    \"final_loss\": 0.314557053602261,\n",
      "    \"training_time_seconds\": 0.02087998390197754,\n",
      "    \"test_accuracy\": 0.0,\n",
      "    \"test_precision\": 0.0,\n",
      "    \"test_recall\": 0.0,\n",
      "    \"test_f1\": 0.0,\n",
      "    \"test_mse\": 0.5746,\n",
      "    \"test_rmse\": 0.758,\n",
      "    \"test_mae\": 0.5579,\n",
      "    \"test_r2\": 0.6495\n",
      "  },\n",
      "  \"mlp_model\": {\n",
      "    \"architecture\": [\n",
      "      12,\n",
      "      64,\n",
      "      32,\n",
      "      16,\n",
      "      8,\n",
      "      1\n",
      "    ],\n",
      "    \"n_hidden_layers\": 4,\n",
      "    \"total_parameters\": 3585,\n",
      "    \"learning_rate\": 0.0005,\n",
      "    \"n_iterations\": 4000,\n",
      "    \"initial_loss\": 6.428935842411034,\n",
      "    \"final_loss\": 0.21074853871008836,\n",
      "    \"training_time_seconds\": 2.9537837505340576,\n",
      "    \"test_accuracy\": 0.0,\n",
      "    \"test_precision\": 0.0,\n",
      "    \"test_recall\": 0.0,\n",
      "    \"test_f1\": 0.0,\n",
      "    \"test_mse\": 0.5457,\n",
      "    \"test_rmse\": 0.7387,\n",
      "    \"test_mae\": 0.5236,\n",
      "    \"test_r2\": 0.6671\n",
      "  },\n",
      "  \"improvement\": 0.0289,\n",
      "  \"improvement_percentage\": 5.03,\n",
      "  \"baseline_better\": false,\n",
      "  \"analysis\": \"\\nTODO: Write your analysis here (minimum 200 words)\\n\\nAddress these questions:\\n1. Which model performed better and by how much?\\n2. Why do you think one model outperformed the other?\\n3. What was the computational cost difference (training time)?\\n4. Any surprising findings or challenges you faced?\\n5. What insights did you gain about neural networks vs linear models?\\n\\nWrite your thoughtful analysis here. Be specific and reference your actual results.\\nCompare the metrics, discuss the trade-offs, and explain what you learned.\\n\\nMy answer:\\nIn comparing the baseline linear regression model with the multi-layer perceptron (MLP) for predicting house prices, the MLP slightly outperformed \\nthe baseline across all key metrics. \\nMLP has slightly lower errors than baseline model across all three metrics error metrics MSE, RMSE and MAE which indicates better predictions \\non average.\\nHowever the R\\u00b2 Score with MLP was 0.6671 vs the baseline model scroe of 0.6495. This shows MLP explains slightly more variance in house prices.\\nThe improvement is modest, showing that while the neural network can capture non-linear relationships, the linear model already \\ncaptures most of the structure in the data. \\nThe MLP\\u2019s advantage likely comes from its ability to model subtle non-linear interactions and its reliance on properly scaled inputs, \\nbut this came with a higher computational cost since it requires iterative training and more resources compared to the almost \\ninstant training of the linear model. \\nInitially saw extreme errors and negative R\\u00b2 values due to mismatched scaling, which highlighted the importance of consistent preprocessing. \\nOverall, the comparison demonstrates that neural networks can provide slight improvements over simple linear models, \\nbut for structured tabular datasets, simple models can be efficient, while neural networks require careful tuning to outperform the base model.\\n\",\n",
      "  \"analysis_word_count\": 286,\n",
      "  \"baseline_loss_decreased\": true,\n",
      "  \"mlp_loss_decreased\": true,\n",
      "  \"baseline_converged\": true,\n",
      "  \"mlp_converged\": true\n",
      "}\n",
      "\n",
      "======================================================================\n",
      "‚úÖ All required fields are filled!\n",
      "\n",
      "üéâ You're ready to submit!\n",
      "\n",
      "Next steps:\n",
      "1. Kernel ‚Üí Restart & Clear Output\n",
      "2. Kernel ‚Üí Restart & Run All\n",
      "3. Verify no errors\n",
      "4. Save notebook\n",
      "5. Rename as: YourStudentID_assignment.ipynb\n",
      "6. Submit to LMS\n"
     ]
    }
   ],
   "source": [
    "# Test the output\n",
    "import json\n",
    "\n",
    "try:\n",
    "    results = get_assignment_results()\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"ASSIGNMENT RESULTS SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(json.dumps(results, indent=2, default=str))\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing = []\n",
    "    def check_dict(d, prefix=\"\"):\n",
    "        for k, v in d.items():\n",
    "            if isinstance(v, dict):\n",
    "                check_dict(v, f\"{prefix}{k}.\")\n",
    "            elif (v == 0 or v == \"\" or v == 0.0 or v == []) and \\\n",
    "                 k not in ['improvement', 'improvement_percentage', 'baseline_better', \n",
    "                          'baseline_converged', 'mlp_converged', 'total_parameters',\n",
    "                          'test_accuracy', 'test_precision', 'test_recall', 'test_f1',\n",
    "                          'test_mse', 'test_rmse', 'test_mae', 'test_r2']:\n",
    "                missing.append(f\"{prefix}{k}\")\n",
    "    \n",
    "    check_dict(results)\n",
    "    \n",
    "    if missing:\n",
    "        print(f\"‚ö†Ô∏è  Warning: {len(missing)} fields still need to be filled:\")\n",
    "        for m in missing[:15]:  # Show first 15\n",
    "            print(f\"  - {m}\")\n",
    "        if len(missing) > 15:\n",
    "            print(f\"  ... and {len(missing)-15} more\")\n",
    "    else:\n",
    "        print(\"‚úÖ All required fields are filled!\")\n",
    "        print(\"\\nüéâ You're ready to submit!\")\n",
    "        print(\"\\nNext steps:\")\n",
    "        print(\"1. Kernel ‚Üí Restart & Clear Output\")\n",
    "        print(\"2. Kernel ‚Üí Restart & Run All\")\n",
    "        print(\"3. Verify no errors\")\n",
    "        print(\"4. Save notebook\")\n",
    "        print(\"5. Rename as: YourStudentID_assignment.ipynb\")\n",
    "        print(\"6. Submit to LMS\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in get_assignment_results(): {str(e)}\")\n",
    "    print(\"\\nPlease fix the errors above before submitting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üì§ Before Submitting - Final Checklist\n",
    "\n",
    "- [ ] **All TODO sections completed**\n",
    "- [ ] **Both models implemented from scratch** (no sklearn models!)\n",
    "- [ ] **get_assignment_results() function filled accurately**\n",
    "- [ ] **Loss decreases for both models**\n",
    "- [ ] **Analysis ‚â• 200 words**\n",
    "- [ ] **All cells run without errors** (Restart & Run All)\n",
    "- [ ] **Visualizations created**\n",
    "- [ ] **File renamed correctly**: YourStudentID_assignment.ipynb\n",
    "\n",
    "---\n",
    "\n",
    "## ‚è≠Ô∏è What Happens Next\n",
    "\n",
    "After submission:\n",
    "1. ‚úÖ Your notebook will be **auto-graded** (executes automatically)\n",
    "2. ‚úÖ You'll receive a **verification quiz** (10 questions, 5 minutes)\n",
    "3. ‚úÖ Quiz questions based on **YOUR specific results**\n",
    "4. ‚úÖ Final score released after quiz validation\n",
    "\n",
    "**The verification quiz ensures you actually ran your code!**\n",
    "\n",
    "---\n",
    "\n",
    "**Good luck! üöÄ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
